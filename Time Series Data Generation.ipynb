{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data Generation\n",
    "This involves the generation of the data for time series analysis results for the given EEG data. The current analysis involves the EDF files of 6 different patients. The number of sampling points vary for the data as the machine used for the analysis varies and the condition in which the data was acquired also varies.\n",
    "\n",
    "Using the pandas library the data in RAW EDF files can be analysed further to give the CSV files with the data of interest. \n",
    "\n",
    "### Spherical Splines to remove bad channels in EEG data\n",
    "\n",
    "The mapping of the Scalp potential (SP) and the Scalp current densities (SCD) are better and accurate enough when the data is approximated using Spherical splines rather than plate splines. \n",
    "\n",
    "This involves the analysis of the statistical quantities of the EEG signal. \n",
    "https://github.com/mne-tools/mne-python/blob/master/examples/preprocessing/plot_interpolate_bad_channels.py\n",
    "https://www.sciencedirect.com/science/article/pii/S1474442202000030#bib40\n",
    "\n",
    "---\n",
    "#### REFERENCES:\n",
    "-  Perrin, F., Pernier, J., Bertrand, O. and Echallier, JF. (1989)\n",
    "   Spherical splines for scalp potential and current density mapping.\n",
    "   Electroencephalography and Clinical Neurophysiology, Feb; 72(2):184-7.\n",
    "- [EDF Files Specification](https://www.edfplus.info/specs/edf.html)\n",
    "- [SET Files Specification]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = ['Fpz', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'F8', 'T4', 'T6', 'A2', 'O2', 'C4', 'P4']\n",
    "file_names = []\n",
    "file_csv_names = []\n",
    "\n",
    "def read_edf():\n",
    "    '''\n",
    "    Reads the edf files from the data folder\n",
    "    '''\n",
    "    path = os.getcwd() + '\\\\data\\\\'\n",
    "    files = []\n",
    "    print(\"Reading files...\")\n",
    "    for f in os.listdir(path):\n",
    "        global file_names\n",
    "        files.append(mne.io.read_raw_edf(path+f, preload=True))\n",
    "        file_names.append(f)\n",
    "        print(f\"Reading {f} now..\")\n",
    "    print('Reading successfully completed!')\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_info(files):\n",
    "    '''\n",
    "    Gets the info from the patients and displays it\n",
    "    '''\n",
    "    for index, item in enumerate(files):\n",
    "        print(f\"> Record Information of patient {index+1}:\\n{item.info}\")\n",
    "        print(\"-\"*40)\n",
    "    print('Information generated!')\n",
    "    return True\n",
    "\n",
    "def set_montage(files, montage):\n",
    "    for index, f in enumerate(files):\n",
    "        print(f\"Setting montage for patient {index+1}\")\n",
    "        files[index].set_montage(montage)\n",
    "        print(f\"Patient {index+1}\")\n",
    "        print(\"Sampling frequency\")\n",
    "        print(f.info[\"sfreq\"])\n",
    "        print(\"LPF freq:\")\n",
    "        print(f.info[\"lowpass\"])\n",
    "        print(f\"Length (s): {f._data[-1].shape[0]/f.info['sfreq']}\") # get the data length\n",
    "        print('-'*20)\n",
    "    return (\"Setting montage completed!\")\n",
    "            \n",
    "def to_csv(files):\n",
    "    global file_csv_names\n",
    "    global file_names\n",
    "    for index, f in enumerate(files):\n",
    "        print(files[index]._data.shape) # 36 rows each corresponding to a channel from the required list of channels\n",
    "        df = pd.DataFrame()\n",
    "        dictOfChannels = { i : ch_names[i] for i in range(0, len(ch_names) ) }\n",
    "        print(f'appending channels to the dataframe {file_names[index]}')\n",
    "        for index1, channel in enumerate(files[index].info[\"ch_names\"]):\n",
    "            if channel in ch_names:\n",
    "                curr = files[index]._data[:][index1]\n",
    "                df = df.append(pd.Series(curr), ignore_index= True)\n",
    "                \n",
    "        df = df.transpose()\n",
    "        df.rename(columns=dictOfChannels, inplace=True)\n",
    "        print(\"*\"*20)\n",
    "        for f in file_names:\n",
    "              file_csv_names.append(f[:-4].strip()+'.csv')\n",
    "        path = os.getcwd() + '\\\\csv_clean\\\\'\n",
    "        print(f\"Writing CSV file to {path+file_csv_names[index]}\")\n",
    "        df.to_csv(path+file_csv_names[index], header = True)\n",
    "        print('CSV written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Reading AB sz1.edf now..\n",
      "Reading AI sz1.edf now..\n",
      "Reading AI sz2.edf now..\n",
      "Reading CR sz1.edf now..\n",
      "Reading CR sz2.edf now..\n",
      "Reading CR sz3.edf now..\n",
      "Reading DM sz1.edf now..\n",
      "Reading JM sz1.edf now..\n",
      "Reading JM sz2.edf now..\n",
      "Reading JM sz3.edf now..\n",
      "Reading JM sz4.edf now..\n",
      "Reading JM sz5.edf now..\n",
      "Reading KS sz1.edf now..\n",
      "Reading successfully completed!\n"
     ]
    }
   ],
   "source": [
    "files = read_edf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the columns under consideration in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 99200)\n",
      "appending channels to the dataframe AB sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\AB sz1.csv\n",
      "CSV written\n",
      "(36, 130400)\n",
      "appending channels to the dataframe AI sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\AI sz1.csv\n",
      "CSV written\n",
      "(36, 307200)\n",
      "appending channels to the dataframe AI sz2.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\AI sz2.csv\n",
      "CSV written\n",
      "(36, 31200)\n",
      "appending channels to the dataframe CR sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\CR sz1.csv\n",
      "CSV written\n",
      "(36, 59200)\n",
      "appending channels to the dataframe CR sz2.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\CR sz2.csv\n",
      "CSV written\n",
      "(36, 73600)\n",
      "appending channels to the dataframe CR sz3.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\CR sz3.csv\n",
      "CSV written\n",
      "(47, 83456)\n",
      "appending channels to the dataframe DM sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\DM sz1.csv\n",
      "CSV written\n",
      "(26, 77000)\n",
      "appending channels to the dataframe JM sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\JM sz1.csv\n",
      "CSV written\n",
      "(26, 31000)\n",
      "appending channels to the dataframe JM sz2.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\JM sz2.csv\n",
      "CSV written\n",
      "(26, 21000)\n",
      "appending channels to the dataframe JM sz3.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\JM sz3.csv\n",
      "CSV written\n",
      "(26, 22000)\n",
      "appending channels to the dataframe JM sz4.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\JM sz4.csv\n",
      "CSV written\n",
      "(26, 51000)\n",
      "appending channels to the dataframe JM sz5.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\JM sz5.csv\n",
      "CSV written\n",
      "(36, 71200)\n",
      "appending channels to the dataframe KS sz1.edf\n",
      "********************\n",
      "Writing CSV file to C:\\Users\\Lingesh K\\Desktop\\EpilepticSeizurePrediction\\csv_clean\\KS sz1.csv\n",
      "CSV written\n"
     ]
    }
   ],
   "source": [
    "to_csv(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the metadata in an EDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0].info # Prints the info of all the meta data in one edf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the montage for the EDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the montage to the standard 10-20 system\n",
    "montage = mne.channels.read_montage(kind='standard_1020', ch_names=ch_names)\n",
    "set_montage(files, montage) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files[0].info[\"dig\"]) # Gives the details of the digitization of the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0].set_eeg_reference(ref_channels=['Ref']) # Set the reference channel for the file AB sz1.edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the Maximum and Minimum value of first patient EDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = files[0]._data\n",
    "num = curr.shape[0]\n",
    "print(f\"Number of channels for patient 1: {num}\")\n",
    "# plotting the maximum and minimum of each channel\n",
    "for i in range(num):\n",
    "    print(f\"channel {i+1}: {files[0].info['ch_names'][i]}\")\n",
    "    print(f\"Minimum : int({min(curr[i])*1e+6}) Maximum: int({max(curr[i])*1e+6})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading an EDF file and Converting to CSV file \n",
    "\\['Event',\n",
    " 'Ref',\n",
    " 'X1',\n",
    " 'X2',\n",
    " 'X3',\n",
    " 'X4',\n",
    " 'X5',\n",
    " 'X6',\n",
    " 'X7',\n",
    " 'X8',\n",
    " 'X9',\n",
    " 'X10',\n",
    " 'OSAT',\n",
    " 'Status'\\] are the channels that are ignored for the ICA procedure. This gives a 22 component result of weighted electrodes. From this, the best 13 channels are chosen and the data is taken for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 307200)\n",
      "CSV Written\n"
     ]
    }
   ],
   "source": [
    "src_path = os.getcwd() + '\\\\Denoised Data\\\\denoised.edf'\n",
    "file = mne.io.read_raw_edf(src_path, preload=True)\n",
    "print(file._data.shape)\n",
    "df = pd.DataFrame()\n",
    "ch_names = ['Fpz', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'F8', 'T4', 'T6', 'A2', 'O2', 'C4', 'P4']\n",
    "dictOfChannels = { i : ch_names[i] for i in range(0, len(ch_names) ) }\n",
    "for index1, channel in enumerate(file.info[\"ch_names\"]):\n",
    "    if channel in ch_names:\n",
    "        curr = file._data[:][index1]\n",
    "        df = df.append(pd.Series(curr), ignore_index= True)\n",
    "df = df.transpose()\n",
    "df.rename(columns=dictOfChannels, inplace=True)\n",
    "df.to_csv(os.getcwd()+'\\\\Denoised Data\\\\denoised.csv', header=True)\n",
    "print('CSV Written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
